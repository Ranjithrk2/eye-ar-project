<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>AR Eye Learning</title>

<script src="https://aframe.io/releases/1.4.2/aframe.min.js"></script>
<script src="https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar.js"></script>

<style>
body{
  margin:0;
  overflow:hidden;
  background:black;
}
</style>
</head>

<body>

<a-scene
  embedded
  arjs="sourceType: webcam; debugUIEnabled: false;"
  vr-mode-ui="enabled: false"
  renderer="logarithmicDepthBuffer: true;"
>

<a-marker preset="hiro" id="marker">

  <!-- MODEL CONTAINER -->
  <a-entity id="modelContainer"
            rotation="0 0 0"
            scale="2 2 2">

      <a-entity
        gltf-model="models/eye.glb"
        position="0 0 0"
        rotation="0 0 0">
      </a-entity>

  </a-entity>

</a-marker>

<!-- CAMERA WITHOUT CURSOR -->
<a-entity camera></a-entity>

</a-scene>


<script>

//////////////////////////////////////////////////
// VOICE EXPLANATION ABOUT HUMAN EYE
//////////////////////////////////////////////////

const explanation =
"The human eye is a complex and important sensory organ that allows us to see the world around us. " +
"Light first enters through the cornea, which is the transparent front surface of the eye. " +
"The iris controls the size of the pupil and regulates how much light enters. " +
"Behind the pupil, the lens focuses light onto the retina at the back of the eye. " +
"The retina converts light into electrical signals that travel through the optic nerve to the brain. " +
"The brain then processes these signals to create the images we see. " +
"The human eye works very similar to a camera, capturing and focusing light to produce vision.";


function speak(){

  if(!('speechSynthesis' in window)) return;

  const msg = new SpeechSynthesisUtterance(explanation);
  msg.rate = 0.9;
  msg.pitch = 1;
  msg.volume = 1;

  window.speechSynthesis.cancel();
  window.speechSynthesis.speak(msg);
}


// Speak when marker detected
document.querySelector("#marker").addEventListener("markerFound", ()=>{
  speak();
});



//////////////////////////////////////////////////
// ROTATE + ZOOM CONTROLS
//////////////////////////////////////////////////

const container = document.getElementById("modelContainer");

let isDragging = false;
let previousX = 0;
let previousY = 0;
let currentScale = 2;


// TOUCH START
document.addEventListener("touchstart", (e)=>{

  if(e.touches.length === 1){
    isDragging = true;
    previousX = e.touches[0].clientX;
    previousY = e.touches[0].clientY;
  }

});


// TOUCH MOVE ROTATE
document.addEventListener("touchmove", (e)=>{

  if(isDragging && e.touches.length === 1){

    let deltaX = e.touches[0].clientX - previousX;
    let deltaY = e.touches[0].clientY - previousY;

    let rotation = container.getAttribute("rotation");

    rotation.y += deltaX * 0.5;
    rotation.x += deltaY * 0.5;

    container.setAttribute("rotation", rotation);

    previousX = e.touches[0].clientX;
    previousY = e.touches[0].clientY;
  }

});


// TOUCH END
document.addEventListener("touchend", ()=>{
  isDragging = false;
});



// PINCH ZOOM
let initialDistance = null;

document.addEventListener("touchmove", (e)=>{

  if(e.touches.length === 2){

    let dx = e.touches[0].clientX - e.touches[1].clientX;
    let dy = e.touches[0].clientY - e.touches[1].clientY;

    let distance = Math.sqrt(dx*dx + dy*dy);

    if(initialDistance === null){
      initialDistance = distance;
    }else{

      let scaleChange = distance / initialDistance;

      currentScale = currentScale * scaleChange;

      currentScale = Math.min(Math.max(currentScale, 1), 5);

      container.setAttribute("scale",
        `${currentScale} ${currentScale} ${currentScale}`);

      initialDistance = distance;
    }

  }

});


document.addEventListener("touchend", ()=>{
  initialDistance = null;
});

</script>

</body>
</html>